---
title: "Case Study: How Does a Bike-Share Navigate Speedy Success?"
author: "Erik Emilsson"
date: "20 December 2022"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*This project is part of the Google Data Analytics Certificate on Coursera and *
*the dataset and the fictional problem comes from Track 1 How does a bike-share*
*navigate speedy business. I am using R in R-markdown for data import, cleaning*
*and visualization as well as the final reporting. R-markdown can do all these *
*steps and having everything in one place keeps track of the assumptions and *
*steps of the analysis for transparency and reproducibility*

**TABLE OF CONTENTS**
1) Business Task Background
2) Importing Libraries, Data Import and Dataset
3) Data Exploration and Cleaning
4) Analyzing the Questions
   a) How are the different bike types used by members and non-members?
   b) How is the trip time different for members and non-members?
   c) How are the bikes used throughout the year?
5) Evaluation and conclusions

# 1.Business Task Background
Cyclist is a bike/share program with over 5,800 bikes and 600 docking stations. 
Currently there are two types of riders: 1) **casual riders** (those who buy 
single-ride or full-day passes), and 2) **annual members a.k.a. Cyclistic members**. 

The goal is to *maximize the number of annual memberships for the company by* 
*converting more casual riders to annual members*. Lily Moreno (director of 
marketing) and the Cyclistic finance analysts have concluded that that annual 
members are more profitable than casual riders. Before this, Cyclistic have 
focused on building general awareness and appealing to broad consumer segments.

Currently 8 percent of riders use assistive options (e.g. reclining bikes, hand 
tricycles, and cargo bikes) while the rest use traditional bikes. Those who use 
traditional bikes are more likely to be casual riders, but about 30 percent of 
them use the service to commute to work each day.

Of the the following three questions that will guide the larger scope of the 
future marketing program, this report will only answer the first question:

* <mark>**How do annual members and casual riders use Cyclistic bikes**</mark>
  <mark>**differently?**</mark>
* Why would casual riders buy Cyclistic annual memberships?
* How can Cyclistic use digital media to influence casual riders to become 
annual members?

The stakeholders are:

* Lily Moreno, director of marketing and my fictional manager,
* The Cyclistic marketing analytics team (which I am part of), which supports 
  the Cyclistic marketing strategy with data, and
* The Cyclistic executive team that will decide if the recommended marketing 
  program is approved or not.
  
# 2. Importing Libraries, Data Import and Dataset

```{r Import Libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(skimr)
library(janitor)
library(lubridate)
library(openxlsx)
library(anytime)
library(ggridges)
library(ggmap)
```


The dataset to represent Cyclistic bike share service bike data comes from Divvy, 
Lyft and Scooters, LLC ("Bikeshare") data. See the licence agreement for more 
information https://ride.divvybikes.com/data-license-agreement. 
The past 12 months (March 2022 to Febuary 2023) of historical trip data was 
downloaded from the database in CSV format to a Google Drive location,  
then uploaded to BigQuery. After this, the 12 files were appended and 
finally exported as a CSV file to be read into this R Markdown report. 
Apart from appending the data, the SQL query essentially left the data unchanged 
so I could showcase the data cleaning process in R, however, in practice it 
should be more practical and efficient to do some of these steps in the SQL 
query instead.

```{r Data Import, echo=FALSE, message=FALSE}
df <- read_csv("202203-202302_AppendedData_withCoordinates.csv", 
               show_col_types = FALSE)
head(df)
```

# 3. Data Exploration and Cleaning

First the headers are renamed to make them clearer. Then the date columns are 
converted to the datetime format. The start dates are extracted then extracted
from the datetime columns, and a trip time column is calculated by taking the 
difference from the start and the end datetimes. The riginal datetime columns 
are then removed.

```{r Rename headers and parse date-times, echo=FALSE, message=FALSE}
df_1 <- df %>% 
  rename(Ride_ID = ride_id) %>%
  rename(Bike_Type = rideable_type) %>%
  rename(Start_Date_and_Time = started_at) %>%
  rename(End_Date_and_Time = ended_at) %>%
  rename(Start_Station_Name = start_station_name) %>%
  rename(Start_Station_ID = start_station_id) %>%
  rename(End_Station_Name = end_station_name) %>%
  rename(End_Station_ID = end_station_id) %>%
  rename(Rider_Type = member_casual) %>%
  rename(Start_Latitude = start_lat) %>%
  rename(Start_Longitude = start_lng) %>%
  rename(End_Latitude = end_lat) %>%
  rename(End_Longitude = end_lng) 
```



```{r parse datetime column, add start date column and add trip time columns}
df_2 <- df_1 %>%
  mutate(
    Start_Date = date(Start_Date_and_Time),
    Start_Date_and_Time = anytime(Start_Date_and_Time, tz = "UTC"),
    End_Date_and_Time = anytime(End_Date_and_Time, tz = "UTC"),
    Trip_Time_Minutes = difftime(End_Date_and_Time, 
                                 Start_Date_and_Time, units="mins")
    )
```

```{r}
summary(df_2)
```

```{r save new df}
df_3 <- df_2
```

Since the trip times and the starting dates have been "extracted" from the 
original datetime columns, the original columns can now be removed.

```{r Remove date-time columns}
df_3 <- select(df_3, -c(Start_Date_and_Time, End_Date_and_Time))
```

```{r}
summary(df_3)
```

Some Trip_Time_Minutes values are negative, which doesn't make sense. These 
negative observations will be removed and additionally any trip times that are
under 2 minutes will also be removed to make sure that the trips were 
intentional by the rider.

```{r}
paste(sum(df_1$Trip_Time_Minutes < 2),
      "rows with trip times below 0 minutes have been removed.")

df_clean <- df_3 %>%
  filter(Trip_Time_Minutes > 2) #removes rows below 0 minutes
```

Now to look at missing values and unique values from the cleaned dataset, as 
well as some statistics by using the skim function.
```{r Skim dataframe}
# There are also missing observations for some of the columns in the head. Using 
# a different function allows us to see more information about missing values and 
# also unique values for each column.
df_skim <- skim_without_charts(df_clean) %>%
  print()
```


```{r Information about missing values, echo=FALSE, message=FALSE}
df_skim %>%
  ggplot(mapping = aes(x = 100*complete_rate, y = skim_variable)) +
  geom_bar(stat= "identity", fill="azure3") +
  labs(
    title="Data completeness per column", 
    subtitle = "Station Names and IDs have missing data!",
    x = "Completeness [%]", 
    y = ""
    ) +
  theme_bw() + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, color = "black", 
                                 size = 10, face = "bold",)
    ) +
  geom_text(aes(label = round(100*complete_rate, digits = 0)), 
            position = position_stack(vjust = 0.97))
```
* Between 15-17% of the data is missing for the start and end station names and 
  IDs. 
  
From the skim function output the following information about *unique* 
observations can be seen:

* There are a total of 5,829,084 observations that each have unique Ride_IDs.
* Bike_Type has 3 unique values 
* Rider_Type has 2 unique values.
* Start and end station names have close to 1700 unique values
* Start and end IDs have close to 1300 unique values.

The unique values of all the locations are much greater than the "over 600 
docking station" that were stated in the case study description. Start/End 
station ID come closest (1302 and 1309 unique values). This divergence
merits an investigation, but will not be the focus of this analysis.

The location IDs consist of a code while the location names are either one or
two street names (presumedly their intersection) with a "&" symbol as their 
denominator. There are more unique location names than location IDs, which
could be for a variety or reasons. It could be misspellings, it could be 
due to some street names being in reverse order, or it could perhaps be due
to there being more than one station per intersection. Again, delving deeper
into the geographical data is not the focus of this analysis as this is instead
something that I might ask a data engineer for more information in a real
world problem. However, to make sure I do my due diligence in this analysis, I 
will export the unique values to Excel and show my observations and 
recommendations here.

```{r duplicate start street names}
uniqueStartStations <- df_3 %>%
  select(Start_Station_ID, Start_Station_Name) %>%
  distinct()
```

```{r duplicate end street names}
uniqueEndStations <- df_3 %>%
  select(End_Station_ID, End_Station_Name) %>%
  distinct()
```

```{r List occurences >1 of Start_Station_Names for UniqueStartStations}
n_occur <- data.frame(table(uniqueStartStations$Start_Station_Name))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of Start_Station_IDs for UniqueStartStations}
n_occur <- data.frame(table(uniqueStartStations$Start_Station_ID))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of End_Station_Names for UniqueEndStations}
n_occur <- data.frame(table(uniqueEndStations$End_Station_Name))
n_occur[n_occur$Freq > 1,]
```

```{r List occurences >1 of End_Station_IDs for UniqueEndStations}
n_occur <- data.frame(table(uniqueEndStations$End_Station_ID))
n_occur[n_occur$Freq > 1,]
```

```{r create Excel sheet to investigate unique occurences of station names and IDs}
Start_stations <- createWorkbook()
addWorksheet(Start_stations, "First_Sheet")
writeData(Start_stations,"First_Sheet", uniqueStartStations)
saveWorkbook(Start_stations, file = "Start_stations_unique.xlsx", overwrite = TRUE)
```

From the investigation I found that:
* There are 17 duplicate start station names (for station ID)
* There are 341 duplicate start station IDs (for staion names)
* There are 17 duplicate end station names (for station ID)
* There are 351 duplicate end station IDs (for station names)
* Station ID codes are sometimes text e.g. street names

The overlap likely means that there are many locations that should be aggregated
into just one if a fair comparison were to be done for the counts of rides
per location. For this reason, also due to the ~15% missing values, there is 
significant bias when using this data, which should be kept in mind when 
looking at the results so as to not make conclusions and decisions on this 
misleading data. 

# 4. Analyzing the Questions

## 4a. How are the different bike types used by members and non-members?

Visualize the counts of rides by bike type and member/casual(non-member):
```{r Annual count of rides}
df_clean %>%
  ggplot() +
  geom_bar(mapping = aes(Bike_Type, fill = Bike_Type), , color = "black") +
  facet_wrap(~Rider_Type) +
  labs(title="Annual rides per bike and rider type", x = "", y = "Rides [count]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

Some observations of the graph:
* There are more rides from members than rides by casual riders in total.
* Casual riders seem to prefer electric bikes over classic bikes while it is the
  opposite for members. However, the difference is not substantial.
* Classic bikes are used much more by members than by casual riders. Electric
  bikes are used about the same amount by members and casual riders.
* Docked bikes were not used at all by members.
* Docked bikes are used much less than any other type of bike.

Some questions that pop up from this first graph are:
* Why don't any annual members use docked bikes at all? Are docked bikes 
  available in the areas where they would be used? What percentage of rides are 
  using docked bikes?
* Why do casual riders prefer electric bikes and members prefer classic bikes?

## 4b. How is the trip time different for members and non-members?

To get some stats on the trip time I'll do some 
* Average travel time for each bike type and membership type
* Min max och each travel time for each bike type and membership type

```{r Annual mean ride times, message=FALSE}
df_clean %>%
  group_by(Rider_Type, Bike_Type) %>%
  summarise(mean = mean(Trip_Time_Minutes), n= n()) %>%
  ggplot(mapping = aes(x = Bike_Type, 
                       y = mean,
                       fill = Bike_Type)) +
  geom_bar(stat= "identity", color = "black") +
  facet_wrap(~Rider_Type) +
  labs(title="Annual Mean ride times per bike and rider type", 
       x = "", 
       y = "duration [minutes]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

This shows that although there aren't as many docked bikes as other types of 
bikes, the total annual ride time is in the same ballpark.

Docked bikes seem to include times that are much greater than electric and 
classic bikes in travel time, so this will be investigated further in a 
distribution.

```{r message=FALSE, warning=FALSE}
ggplot(df_clean,
       aes(x = Trip_Time_Minutes,
           y = Bike_Type,
           fill = Bike_Type)
       ) +
  scale_x_continuous(limits=c(0, 60)) +
  geom_density_ridges() + 
  facet_wrap(~Rider_Type, ncol = 1) +
  theme_ridges() +
  labs(title = "Distribution of trip times under 1 hour", 
       x = "Trip time [minutes]", y = "Rides [count]") +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

The comparison between the trip times for the different bikes shows that the 
electric and classic bikes are quite similar in trip time distribution while 
the docked bikes are on average used for longer. In fact, almost no classic 
and electric bikes are used for longer than 3000 seconds (about 1 hour) while 
some bike users take trips at up to about 1000 seconds (about 3 hours) or 
longer. Since all docked bike users are non-members, this is difference in 
user behavior should be looked at closer.

## 4c. How are the bikes used throughout the year?

The following graphs will plot the distribution of rides throughout the year, 
divided into bike types in the first graph and non-member/member in the second 
graph. Note that the dips in the month of October is due to the cut-off in the 
data being in that month, hence the October 2021 and October 2022 data should
be aggregated to get the "real" value for that month.

```{r}
ggplot(df_clean, 
       aes(x = Start_Date, 
           fill = Bike_Type)) +
  geom_density(alpha = 0.4) +
  scale_x_date(date_breaks = "1 months", date_labels = "%b %d") +
  facet_wrap(~Rider_Type, ncol = 1) +
  labs(title = "Trips distribution per day of the year", 
       x = "Trip day", y = "") +
  theme(axis.text.y=element_blank(),  #remove y axis labels
        axis.ticks.y=element_blank()  #remove y axis ticks
        ) +
  theme(plot.title = element_text(hjust = 0.5, color = "black", 
                              size = 14, face = "bold"))
```

Bike usage is higher between May-October and lower between September-April.

There is not much difference between what time of year users of different bike 
types ride bikes except for a dip of relative electric bike usage in June.

Members have a more even distribution of usage for throughout the year compared 
to casual riders. Essentially, the cooler months of September-May casual riders 
use the service less relative to members while in the warmer months June-October 
they use the bikes more relative to members. The difference is most extreme in
June-August.

As the summer months are where most casual riders are using the bikes, there 
could be an opportunity to run campaigns during these months.

## 4d. Where are the bikes being used?

```{r}
ggplot(df_clean, aes(Start_Station_Name, Freq)) +
  geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
  labs(title="Bar Chart", 
       subtitle="Manufacturer of vehicles", 
       caption="Source: Frequency of Manufacturers from 'mpg' dataset") + 
  theme(axis.text.x = element_text(angle=65, vjust=0.6))

df_clean %>% 
  group_by(broad_field,field) %>%
  summarise(n=sum(n_phds, na.rm=TRUE)) %>%
  arrange(desc(n))%>%
  head(30)%>%
  ggplot(aes(x=reorder(field,n),y=n, fill=broad_field)) +
  xlab("field")+
  geom_col() + coord_flip()
```


## 5. Evaluation and conclusions

The lack of data on station names (of about 15%) and geographical coordinates 
(less than 1%) can mean that the results are skewed, especially if the lack of 
data for these observations are not spread evenly. For example, if there are 
specific stations that don't show the data, then there could be a significant 
difference from the reported and actual number of rides in that area.

Recommendations for further analysis:
* Look into why docked bike users aren't members. Like: why don't any annual 
  members use docked bikes? Are memberships available for riders of docked bikes 
  and/or are the riders aware of the memberships?
* See why some docked bike rides are up to 40,000minutes long (almost 10 days). 
  These riders are likely more intersted in a membership because they're paying 
  a lot for the rentals by only being casual riders.
* Collect data on the behavior of specific users as well, not only per ride. 
  Tracking individuals can give more insight into how the users use the bikes.
* Look into why there is missing data and if there is more than one reason for 
  the 15% that don't show up in station names & IDs.
* Why do casual riders prefer electric bikes and members prefer classic bikes? 
  Perform a questionaire to capture what casual members are drawn to regarding 
  electric bikes and if there is anything Cyclistic can do to make a membership 
  more palatable from their answers.
* Run campaigns during the months of heavy casual rider bike use, during 
  the months of June-August.
  
  
# TO DO
I think I could shorten the text by omitting some things that don't specifically 
have to do with the business task that I specifically am answering with my analysis. 
Alternatively use some formatting to make it different from the main text.

I could include the link to the data and be clearer with the problems with the 
data in a separate section in the Data Import, Exploration, and Cleaning chapter.

I could write an introduction to the analysis phase with how I organized and 
formatted data for the analysis, including statistical calculations.

I'm most proud of the distribution of trip times, because I felt that it was a 
simple way of showing that there is a difference for the bike types while also 
showing how they are different, all in one graph. 
I think I should look over the graphs again to make sure that the main messages 
are even clearer by checking the labels again.